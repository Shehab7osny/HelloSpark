# HelloSpark
### Loading and Processing Data using Spark (Scala)

## Table of contents
* [Introduction](#Introduction)
* [Project Aim](#technologies)
* [Project Technical Details](#setup)

## Introduction
Apache Spark is a lightning-fast cluster computing technology, designed for fast computation. It is based on Hadoop MapReduce and it extends the MapReduce model to efficiently use it for more types of computations, which includes interactive queries and stream processing. The main feature of Spark is its in-memory cluster computing that increases the processing speed of an application.

Spark is designed to cover a wide range of workloads such as batch applications, iterative algorithms, interactive queries and streaming. Apart from supporting all these workload in a respective system, it reduces the management burden of maintaining separate tools.

## Project Aim

## Project Technical Details
