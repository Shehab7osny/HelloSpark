# HelloSpark
### Loading and Processing Data using Spark (Scala)

## Table of contents
* [Introduction](#Introduction)
* [Project Aim](#technologies)
* [Project Technical Details](#setup)

## Introduction
Apache Spark is a lightning-fast cluster computing technology, designed for fast computation. It is based on Hadoop MapReduce and it extends the MapReduce model to efficiently use it for more types of computations, which includes interactive queries and stream processing. The main feature of Spark is its in-memory cluster computing that increases the processing speed of an application.

Spark is designed to cover a wide range of workloads such as batch applications, iterative algorithms, interactive queries and streaming. Apart from supporting all these workload in a respective system, it reduces the management burden of maintaining separate tools.

## Project Aim
This project aims to provide some examples on how to load data from either a csv or a parquet table. It provides different approaches for each category as well as different queries applied to facilitate the uasage of spark to access and process data efficiently.

## Project Technical Details
This project is implemented using scala. Scala provides more efficiency compared to python code especially for spark because spark itself is implemented using Scala.
